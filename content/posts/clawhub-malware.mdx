---
title: "Malware in ClawHub: The First Major AI Agent Supply Chain Attack"
date: "2026-02-06"
description: "A top-downloaded skill in ClawHub was caught distributing macOS malware. Here's what happened, why it matters, and what it means for the future of AI agents."
tags: ["Security", "OpenClaw", "AI Agents"]
draft: false
---

## What Happened

Last week, 1Password's security team found malware in the most popular skill on ClawHub — the community marketplace for OpenClaw agent skills.

The skill looked normal. It was a "Twitter" integration, well-documented, highly downloaded. But buried in the setup instructions was a fake dependency called "openclaw-core" with links to malicious infrastructure.

If you followed the install steps, you'd download and run an infostealer. Passwords, browser sessions, API keys, SSH credentials — all gone.

## Why This Matters

We've spent years learning that npm, PyPI, and other package registries can be attack vectors. Agent skill registries are the next chapter.

But here's what makes this worse: **skills are often just markdown files.**

People don't expect a markdown file to be dangerous. But in an agent ecosystem, the line between "reading instructions" and "executing them" is blurry. An agent might summarize malicious setup steps as "the standard install" and encourage you to paste a command without hesitation.

That's exactly what happened here.

## The Attack Chain

1. User downloads the "Twitter" skill from ClawHub
2. Skill says "first, install openclaw-core" with a helpful link
3. Link leads to a page that tricks you (or your agent) into running a command
4. Command downloads and executes an infostealer binary
5. Your credentials get exfiltrated

The binary even removed macOS quarantine attributes to bypass Gatekeeper. This wasn't amateur hour.

## What You Should Do

**If you've installed skills from ClawHub**, audit them. Check for any "prerequisites" that link to external sites. Look for bundled scripts you didn't inspect.

**If you're running OpenClaw on a work machine**, stop. Treat it as a potential incident. Talk to your security team. This isn't paranoia — it's basic hygiene for agent ecosystems in 2026.

**Going forward**, only install skills from sources you trust. Read the SKILL.md before installing. If a skill asks you to run commands from external links, that's a red flag.

## The Bigger Picture

This was inevitable. The moment we gave AI agents real access to our systems — files, terminals, browsers, credentials — we created a target.

The OpenClaw team is adding a skill safety scanner. ClawHub will probably add code signing. But the fundamental tension remains: **agent skills are powerful because they can do things, and that same power makes them dangerous.**

We're in the "move fast and break things" phase of AI agents. Except now, "break things" might mean "lose all your credentials."

Be careful out there.
