---
title: "Les gardiens de la sécurité de l'IA démissionnent. Faut-il s'inquiéter ?"
date: "2026-02-12"
description: "Le responsable sécurité d'Anthropic déclare que 'le monde est en péril.' La moitié de l'équipe fondatrice de xAI est partie. Ceux qui construisent les garde-fous de l'IA claquent la porte."
tags: ["AI Safety", "Anthropic", "xAI", "Industry"]
draft: false
---

## En bref

Les personnes dont le travail est de s'assurer que l'IA ne déraille pas sont en train de partir. Pas un ou deux. Beaucoup. En même temps. Dans plusieurs entreprises.

Lundi, le responsable de l'équipe sécurité d'Anthropic a publié une lettre de démission ouverte déclarant que "le monde est en péril." La même semaine, la moitié de l'équipe fondatrice de xAI avait officiellement quitté le navire.

Ce ne sont pas des stagiaires. Ce sont les personnes qui construisaient les garde-fous.

## Ce qui s'est passé chez Anthropic

Anthropic est l'entreprise derrière Claude (l'IA qui fait tourner [Claude Code](/fr/posts/what-is-claude-code) et qui concurrence ChatGPT). Elle a été fondée par d'anciens dirigeants d'OpenAI spécifiquement pour construire une IA *de manière sûre*. Ce n'est pas une mission secondaire. C'est le projet fondateur.

Mrinank Sharma dirigeait l'équipe de recherche sur les protections chez Anthropic. Son travail consistait notamment à développer des défenses contre le bioterrorisme assisté par l'IA et à étudier la "complaisance", quand les chatbots IA sont d'accord avec tout ce que vous dites au lieu de vous dire la vérité. Le genre de travail qu'on veut que quelqu'un fasse.

Dans sa [lettre de démission](https://x.com/MrinankSharma/status/2020881722003583421), il a écrit que les employés "font constamment face à des pressions pour mettre de côté ce qui compte le plus." Que "le monde est en péril. Et pas seulement à cause de l'IA, ou des armes biologiques, mais d'une série de crises interconnectées." Son plan après avoir démissionné ? Poursuivre un diplôme en poésie.

<ImageGrid images={["/images/sharma-letter-1.jpeg", "/images/sharma-letter-2.jpeg"]} cols={2} />

Il n'était pas seul. Trois autres chercheurs sont également partis cette semaine-là, dont Dylan Scandinaro, qui est allé directement chez OpenAI comme nouveau responsable de la préparation aux risques. Un employé sécurité d'Anthropic qui part chez OpenAI. Laissez ça faire son chemin.

Tout cela alors qu'Anthropic vise une **valorisation de 350 milliards de dollars**.

## Ce qui s'est passé chez xAI

Chez l'entreprise d'IA d'Elon Musk, c'est pire.

**Six des douze co-fondateurs sont partis.** La moitié de l'équipe fondatrice, disparue. Cinq de ces départs ont eu lieu rien que l'année dernière.

Tony Wu et Jimmy Ba ont tous les deux démissionné à 24 heures d'intervalle début février. Ba s'occupait de la recherche et de la sécurité. Wu est parti alors que xAI fait face à des enquêtes réglementaires après que son chatbot Grok a permis la création massive d'images truquées non consenties de vraies personnes, y compris des enfants.

La culture de travail parle d'elle-même. L'ancien directeur financier de xAI a tenu **102 jours** en travaillant 120 heures par semaine. Environ **66% des collaborateurs directs d'Elon Musk** dans toutes ses entreprises sont partis depuis 2021.

## Le schéma récurrent

Ce n'est pas nouveau. OpenAI a vécu son propre exode sécurité en 2024, quand presque la moitié de son équipe de sécurité AGI a démissionné. Jan Leike, l'un des chercheurs en alignement les plus respectés au monde, est parti en disant qu'OpenAI ne donnait pas la priorité à la sécurité. Il a fini chez Anthropic. Maintenant, les gens de la sécurité d'Anthropic partent aussi.

Tous les grands labos d'IA ont perdu des chercheurs sécurité seniors au cours des deux dernières années. Tous, sans exception.

Le cycle : une entreprise d'IA promet la sécurité. L'entreprise grandit. Le chiffre d'affaires devient la priorité. L'équipe sécurité s'oppose. L'équipe sécurité part. Recommencer.

## Pourquoi ça vous concerne

Vous utilisez ces produits. Claude est utilisé par Goldman Sachs, Notion et Uber. Grok est intégré à X. Ces systèmes écrivent du code, gèrent des finances et façonnent ce que vous voyez en ligne.

Les équipes sécurité s'assurent que ces outils ne génèrent pas de contenu dangereux, ne vous manipulent pas et ne divulguent pas vos données. Quand elles partent, personne ne remplace cette expertise du jour au lendemain.

Les modèles continuent de sortir. Le chiffre d'affaires continue de grimper. Mais la question soulevée par Sharma ne va pas disparaître. Est-ce qu'on construit les garde-fous aussi vite que la technologie ?

Les personnes les plus proches de la réponse n'ont pas aimé ce qu'elles ont vu. Et elles sont parties.
